{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTqjcJ1i7fnkorPThTRUjn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSJR741221/DSJackieR/blob/main/Solucion_Reto_SC_63_JacquelineRichard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2nrZ222oY8z",
        "outputId": "fd3396bc-1e1d-4995-b2b0-95ca2d05c043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Información del dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9000 entries, 0 to 8999\n",
            "Data columns (total 17 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   age        9000 non-null   int64 \n",
            " 1   job        9000 non-null   object\n",
            " 2   marital    9000 non-null   object\n",
            " 3   education  9000 non-null   object\n",
            " 4   default    9000 non-null   object\n",
            " 5   balance    9000 non-null   int64 \n",
            " 6   housing    9000 non-null   object\n",
            " 7   loan       9000 non-null   object\n",
            " 8   contact    9000 non-null   object\n",
            " 9   day        9000 non-null   int64 \n",
            " 10  month      9000 non-null   object\n",
            " 11  duration   9000 non-null   int64 \n",
            " 12  campaign   9000 non-null   int64 \n",
            " 13  pdays      9000 non-null   int64 \n",
            " 14  previous   9000 non-null   int64 \n",
            " 15  poutcome   9000 non-null   object\n",
            " 16  y          9000 non-null   object\n",
            "dtypes: int64(7), object(10)\n",
            "memory usage: 1.2+ MB\n",
            "None\n",
            "\n",
            "Datos perdidos por variable:\n",
            "age          0\n",
            "job          0\n",
            "marital      0\n",
            "education    0\n",
            "default      0\n",
            "balance      0\n",
            "housing      0\n",
            "loan         0\n",
            "contact      0\n",
            "day          0\n",
            "month        0\n",
            "duration     0\n",
            "campaign     0\n",
            "pdays        0\n",
            "previous     0\n",
            "poutcome     0\n",
            "y            0\n",
            "dtype: int64\n",
            "Matriz de Confusión - Regresión Logística:\n",
            "[[929 129]\n",
            " [185 557]]\n",
            "Reporte de clasificación - Regresión Logística:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.83      0.88      0.86      1058\n",
            "         yes       0.81      0.75      0.78       742\n",
            "\n",
            "    accuracy                           0.83      1800\n",
            "   macro avg       0.82      0.81      0.82      1800\n",
            "weighted avg       0.82      0.83      0.82      1800\n",
            "\n",
            "Matriz de Confusión Ajustada - Regresión Logística:\n",
            "[[929 129]\n",
            " [185 557]]\n",
            "Matriz de Confusión - Red Neuronal:\n",
            "[[906 152]\n",
            " [139 603]]\n",
            "Matriz de Confusión Ajustada - Red Neuronal:\n",
            "[[887 171]\n",
            " [128 614]]\n",
            "Matriz de Confusión Final:\n",
            "[[876 129]\n",
            " [193 602]]\n",
            "Reporte de clasificación Final:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.82      0.87      0.84      1005\n",
            "         yes       0.82      0.76      0.79       795\n",
            "\n",
            "    accuracy                           0.82      1800\n",
            "   macro avg       0.82      0.81      0.82      1800\n",
            "weighted avg       0.82      0.82      0.82      1800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Importación de librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# Import SimpleImputer for handling missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Paso 2: Cargar los datos a un dataframe 'data'\n",
        "data = pd.read_csv('/content/sample_data/bbank_marketing_RETO_DS_AS.csv')\n",
        "\n",
        "# Paso 3: Información general de la base de datos\n",
        "print(\"Información del dataset:\")\n",
        "print(data.info())  # Número de registros, total de variables, tipos de variables, etc.\n",
        "print(\"\\nDatos perdidos por variable:\")\n",
        "print(data.isnull().sum())  # Muestra la cantidad de datos perdidos\n",
        "\n",
        "# Paso 4: Transformación de variables categóricas\n",
        "# Mostramos las variables categóricas\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "# Usaremos LabelEncoder si hay una variable con pocas categorías, y OneHotEncoder para las variables con muchas categorías\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Paso 5: Transformación de variables numéricas (si es necesario)\n",
        "# Comprobamos si hay variables con sesgo (skewness)\n",
        "#numerical_columns = data.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "for col in numerical_columns:\n",
        "    skewness = data[col].skew()\n",
        "    if abs(skewness) > 1:  # Si el sesgo es mayor que 1, transformamos la variable\n",
        "        # Replace infinite values with NaN\n",
        "        data[col] = data[col].replace([np.inf, -np.inf], np.nan)\n",
        "        # Instead of filling NaN with 0, use the median for imputation before log1p\n",
        "\n",
        "# Paso 6: Definir la variable de salida y las variables de entrada\n",
        "X = data.drop('y', axis=1)  # Variables de entrada\n",
        "y = data['y']  # Variable de salida\n",
        "\n",
        "# Paso 7: Particionar los datos en entrenamiento, validación y prueba (60%, 20%, 20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Define categorical and numerical features\n",
        "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "# Create pipelines for numerical and categorical features\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')), # Impute missing numerical values with mean\n",
        "    ('scaler', StandardScaler()), # Scale numerical features\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')), # Impute missing categorical values with most frequent\n",
        "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore')), # One-hot encode categorical features\n",
        "])\n",
        "\n",
        "# Combine pipelines using ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numerical_pipeline, numerical_features),\n",
        "    ('cat', categorical_pipeline, categorical_features),\n",
        "])\n",
        "\n",
        "# Apply preprocessing to train, validation, and test data\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_val = preprocessor.transform(X_val)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "# Paso 8: Aplicar Regresión Logística\n",
        "# Ajuste de parámetros: por ejemplo, probamos diferentes valores de C (regularización)\n",
        "logreg = LogisticRegression(max_iter=1000, C=0.5, random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones en el conjunto de validación\n",
        "y_val_pred = logreg.predict(X_val)  # Call the predict method with X_val to get predictions\n",
        "\n",
        "# Matriz de confusión para el modelo de Regresión Logística\n",
        "conf_matrix_logreg = confusion_matrix(y_val, y_val_pred)\n",
        "print(\"Matriz de Confusión - Regresión Logística:\")\n",
        "print(conf_matrix_logreg)\n",
        "\n",
        "# Clasificación\n",
        "print(\"Reporte de clasificación - Regresión Logística:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# Ajuste de parámetros: por ejemplo, probamos diferentes valores de C (regularización)\n",
        "logreg = LogisticRegression(max_iter=1000, C=0.5, random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones en el conjunto de validación\n",
        "y_val_pred = logreg.predict(X_val)\n",
        "conf_matrix_logreg = confusion_matrix(y_val, y_val_pred)\n",
        "print(\"Matriz de Confusión Ajustada - Regresión Logística:\")\n",
        "print(conf_matrix_logreg)\n",
        "\n",
        "# Paso 9: Aplicar Red Neuronal\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones en el conjunto de validación\n",
        "y_val_pred_mlp = mlp.predict(X_val)\n",
        "\n",
        "# Matriz de confusión para el modelo de Red Neuronal\n",
        "conf_matrix_mlp = confusion_matrix(y_val, y_val_pred_mlp)\n",
        "print(\"Matriz de Confusión - Red Neuronal:\")\n",
        "print(conf_matrix_mlp)\n",
        "\n",
        "# Ajuste de parámetros: probamos diferentes combinaciones de neuronas y capas ocultas\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(20, 10), max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_val_pred_mlp = mlp.predict(X_val)\n",
        "conf_matrix_mlp = confusion_matrix(y_val, y_val_pred_mlp)\n",
        "print(\"Matriz de Confusión Ajustada - Red Neuronal:\")\n",
        "print(conf_matrix_mlp)\n",
        "\n",
        "# Paso 10: Desempeño final del modelo en el conjunto de prueba\n",
        "best_model = logreg  # Supongamos que el mejor modelo es la regresión logística\n",
        "\n",
        "# Predicciones en el conjunto de prueba\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Matriz de confusión final\n",
        "final_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "print(\"Matriz de Confusión Final:\")\n",
        "print(final_conf_matrix)\n",
        "\n",
        "# Reporte de clasificación final\n",
        "print(\"Reporte de clasificación Final:\")\n",
        "print(classification_report(y_test, y_test_pred))\n"
      ]
    }
  ]
}